{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP-HMM for changepoint detection in RTT timeseries\n",
    "\n",
    "In this notebook we benchmark the HDP-HMM and several classical changepoint detection methods on the dataset introduced by Shao et al. [1].\n",
    "\n",
    "[1] W. Shao, J. Rougier, A. Paris, F. Devienne and M. Viste, \"One-to-One Matching of RTT and Path Changes,\" 2017 29th International Teletraffic Congress (ITC 29), Genoa, 2017, pp. 196-204. https://arxiv.org/pdf/1709.04819.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Glob\n",
    "using Impute\n",
    "using PyPlot\n",
    "using ProgressMeter\n",
    "using Random\n",
    "using Statistics\n",
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Shao17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../../ParsimoniousMonitoring/notebooks/thesis.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_trace(path; fillmissing=false, nomissingcp=false)\n",
    "    trace = CSV.read(path, copycols=true)\n",
    "    \n",
    "    allowmissing!(trace, :rtt)\n",
    "    trace[trace.rtt .<= 0.0, :rtt] .= missing\n",
    "\n",
    "    # Remove change points on missing data points,\n",
    "    # and one time step after.\n",
    "    if nomissingcp\n",
    "        trace[ismissing.(trace.rtt), :cp] .= 0\n",
    "        trace[circshift(ismissing.(trace.rtt), 1), :cp] .= 0\n",
    "    end\n",
    "    \n",
    "    if fillmissing\n",
    "        Impute.locf!(trace.rtt)\n",
    "        Impute.nocb!(trace.rtt)\n",
    "        disallowmissing!(trace, :rtt)\n",
    "    end\n",
    "    \n",
    "    trace\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function benchmark(f, trace; window = 2)\n",
    "    Random.seed!(2020)\n",
    "    rtt = collect(trace.rtt)\n",
    "\n",
    "    # Julia and R arrays are 1-indexed, while Python lists are 0-indexed,\n",
    "    # so we subtract 1 to every indices.\n",
    "    fact = findall(trace.cp .== 1) .- 1\n",
    "    detection = f(rtt) .- 1\n",
    "\n",
    "    # Like in Shao paper, we replace missing values with -3.0 when\n",
    "    # weighting RTT changes.\n",
    "    evaluation_window_weighted(coalesce.(rtt, -3.0), fact, detection, window=window)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function benchmarkall(methods, files; trace_args=Dict())\n",
    "    results = DataFrame(\n",
    "        [String[], String[], Float64[], Float64[], Float64[], Float64[], Float64[]],\n",
    "        [:file, :method, :precision, :recall, :recall_w, :f2, :f2_w]\n",
    "    )\n",
    "\n",
    "    @showprogress for file in files\n",
    "        trace = load_trace(file; trace_args...)\n",
    "        for (name, method) in methods\n",
    "            eval = benchmark(method, trace)\n",
    "            push!(results, (file, name, eval.precision, eval.recall, eval.score, f2(eval), f2w(eval)))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_results(results)\n",
    "    methods = unique(results.method)\n",
    "\n",
    "    metrics = [:precision, :recall, :recall_w, :f2, :f2_w]\n",
    "    names = [\"Precision\", \"Recall\", \"Recall (weighted)\", \"F2\", \"F2 (weighted)\"]\n",
    "    kwargs = Dict(\n",
    "        \"cpt_np&MBIC\" => Dict(:color => \"gray\", :linestyle => \"--\"),\n",
    "        \"cpt_poisson&MBIC\" => Dict(:color => \"purple\", :linestyle => \"--\"),\n",
    "        \"HDP-HMM\" => Dict(:color => \"red\", :label => \"HDPHMM\"),\n",
    "        \"DPMM\" => Dict(:color => \"pink\", :label => \"DPMM\"),\n",
    "    )\n",
    "\n",
    "    fig, axes = subplots(ncols=length(metrics), figsize=(20, 3), sharey=true)\n",
    "    # TODO: Reduce space between boxes\n",
    "\n",
    "    for (ax, metric, name) in zip(axes, metrics, names)\n",
    "        for method in methods\n",
    "            df = results[results.method .== method, metric]\n",
    "            supp = 0:0.001:1\n",
    "            label = replace(method, \"_\" => \"\\\\_\")\n",
    "            label = replace(label, \"&\" => \"\\\\&\")\n",
    "            ax.plot(supp, ecdf(df)(supp); label = label, kwargs[method]...)\n",
    "        end\n",
    "        ax.set_xlabel(name)\n",
    "    end\n",
    "    \n",
    "    axes[1].set_ylabel(\"CDF\")\n",
    "    axes[end].legend(loc=\"upper left\", fontsize=12)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"*.csv\", \"../external/rtt/dataset/real_trace_labelled/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average percentage of missing data\n",
    "mean(map(files) do file\n",
    "    trace = load_trace(file)\n",
    "    sum(ismissing.(trace.rtt)) / length(trace.rtt) * 100\n",
    "end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enablemissing(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = Dict(\n",
    "    # Like in Shao paper, we replace missing values with 1e3.\n",
    "    \"cpt_np&MBIC\"      => rtt -> cpt_np(coalesce.(rtt, 1000.0), \"MBIC\", 3),\n",
    "    \"cpt_poisson&MBIC\" => rtt -> cpt_poisson(coalesce.(rtt, 1000.0), \"MBIC\", 3),\n",
    "    \"HDP-HMM\"          => rtt -> cpt_hmm(coalesce.(rtt, 1000.0)),\n",
    "    \"DPMM\"             => rtt -> cpt_mm(coalesce.(rtt, 1000.0)),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_paper = benchmarkall(methods, files, trace_args=Dict(:fillmissing => false, :nomissingcp => false));\n",
    "results_paper = CSV.read(\"../results/cpt_real_paper.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [:precision, :recall, :recall_w, :f2, :f2_w]\n",
    "combine(groupby(results_paper, :method), [metric => median for metric in metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_fixed = benchmarkall(methods, files, trace_args=Dict(:fillmissing => true, :nomissingcp => true));\n",
    "results_fixed = CSV.read(\"../results/cpt_real_fixed.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [:precision, :recall, :recall_w, :f2, :f2_w]\n",
    "combine(groupby(results_fixed, :method), [metric => median for metric in metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV.write(\"../results/cpt_real_paper.csv\", results_paper);\n",
    "# CSV.write(\"../results/cpt_real_fixed.csv\", results_fixed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
